{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**简单加权融合**：   \n",
    "   回归：算术平均融合，几何平均融合；      \n",
    "   分类：投票   \n",
    "   综合：排序融合，log融合   \n",
    "**stacking、blending**：   \n",
    "   构建多层模型，利用结果再拟合预测。   \n",
    "**boosting、bagging**：   \n",
    "   多树的提升方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 回归、分类概率融合："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.简单加权平均，结果直接融合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pre1 = [1.2,3.2,2.1,6.2]\n",
    "test_pre2 = [0.9,3.1,2.0,5.9]\n",
    "test_pre3 = [1.1,2.9,2.2,6.0]\n",
    "\n",
    "y_test_true = [1,3,2,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Weighted_method(test_pre1,test_pre2,test_pre3,w=[1/3,1/3,1/3]):\n",
    "    Weighted_result = w[0]*pd.Series(test_pre1)+w[1]*pd.Series(test_pre2)+w[2]*pd.Series(test_pre3)\n",
    "    return Weighted_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred1 MAE: 0.1750000000000001\n",
      "Pred2 MAE: 0.07499999999999993\n",
      "Pred3 MAE: 0.10000000000000009\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print('Pred1 MAE:',metrics.mean_absolute_error(y_test_true,test_pre1))\n",
    "print('Pred2 MAE:',metrics.mean_absolute_error(y_test_true,test_pre2))\n",
    "print('Pred3 MAE:',metrics.mean_absolute_error(y_test_true,test_pre3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted_pre MAE: 0.05750000000000027\n"
     ]
    }
   ],
   "source": [
    "w = [0.3,0.4,0.3]\n",
    "Weighted_pre = Weighted_method(test_pre1,test_pre2,test_pre3,w)\n",
    "print('Weighted_pre MAE:',metrics.mean_absolute_error(y_test_true,Weighted_pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Mean_method(test_pre1,test_pre2,test_pre3):\n",
    "#     Mean_result = pd.concat([pd.Series(test_pre1),pd.Series(test_pre2),pd.Series(test_pre3)],axis=1).mean(axis=1)\n",
    "#     return Mean_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stacking融合（回归）**\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "def Stacking_method(train_reg1,train_reg2,train_reg3,y_train_true,test_pre1,test_pre2,test_pre3,model_L2=linear_model.LinearRegression()):\n",
    "    model_L2.fit(pd.concat([pd.Series(train_reg1),pd.Series(train_reg2),pd.Series(train_reg3)],axis=1).values,y_train_true)\n",
    "    Stacking_result = model_L2.predict(pd.concat([pd.Series(test_pre1),pd.Series(test_pre2),pd.Series(test_pre3)],axis=1).values)\n",
    "    return Stacking_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_reg1 = [3.2,8.2,9.1,5.2]\n",
    "train_reg2 = [2.9,8.1,9.0,4.9]\n",
    "train_reg3 = [3.1,7.9,9.2,5.0]\n",
    "\n",
    "y_train_true = [3,8,9,5]\n",
    "\n",
    "test_pre1 = [1.2,3.2,2.1,6.2]\n",
    "test_pre2 = [0.9,3.1,2.0,5.9]\n",
    "test_pre3 = [1.1,2.9,2.2,6.0]\n",
    "\n",
    "y_test_ture = [1,3,2,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking_pre MAE: 0.04213483146067476\n"
     ]
    }
   ],
   "source": [
    "model_L2 = linear_model.LinearRegression()\n",
    "Stacking_pre = Stacking_method(train_reg1,train_reg2,train_reg3,y_train_true,\n",
    "                              test_pre1,test_pre2,test_pre3,model_L2)\n",
    "print('Stacking_pre MAE:',metrics.mean_absolute_error(y_test_true,Stacking_pre))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看出来，模型相对于之前有了进一步提升，注意：第二层Stacking模型不宜选的过于复杂，有过拟合的风险。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LogisticRegression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-94f649bcee48>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 多个单模型融合\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m clfs = [LogisticRegression(solver='lbfgs'),\n\u001b[0m\u001b[0;32m      3\u001b[0m        \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gini'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m        \u001b[0mExtraTreesClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gini'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m        \u001b[0mExtraTreesClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'entropy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LogisticRegression' is not defined"
     ]
    }
   ],
   "source": [
    "# 多个单模型融合\n",
    "clfs = [LogisticRegression(solver='lbfgs'),\n",
    "       RandomForestClassifier(n_estimators=5,n_jobs=-1,criterion='gini'),\n",
    "       ExtraTreesClassifier(n_estimators=5,n_jobs=-1,criterion='gini'),\n",
    "       ExtraTreesClassifier(n_estimators=5,n_jobs=-1,criterion='entropy'),\n",
    "       GradientBoostingClassifier(learning_rate=0.05,subsample=0.5,max_depth=6,n_estimators=5)]\n",
    "\n",
    "# 切分一部分数据作为测试集\n",
    "X,X_predict,y,y_predict = train_test_split(data,target,test_size=0.3,random_state=2020)\n",
    "\n",
    "dataset_blend_train = np.zeros((X.shape[0],len(clfs)))         # 构建 A 的0矩阵\n",
    "dataset_blend_test = np.zeros((X_predict.shape[0],len(clfs)))    # 构建 B 的0矩阵\n",
    "\n",
    "# 5折stacking\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits)\n",
    "skf = skf.split(X,y)\n",
    "\n",
    "for j,clf in enumerate(clfs):  # 遍历每一个模型\n",
    "    \n",
    "    # 依次训练各个单模型\n",
    "    dataset_blend_test_j = np.zeros((X_predict.shape[0],5))  # 单模型0矩阵\n",
    "    for i,(train,test) in enumerate(skf):    # k折交叉验证--训练集--测试集  索引\n",
    "        \n",
    "        # 5折交叉验证，使用第i个部分作预测，剩余部分来训练模型，获得其预测的输出作为第i部分的新特征\n",
    "        X_train,y_train,X_test,y_test = X[train],y[train],X[test],y[test]\n",
    "        clf.fit(X_train,y_train)\n",
    "        y_submission = clf.predict_proba(X_test)[:,1]\n",
    "        dataset_blend_train[test,j] = y_submission    # 用每一次验证集的预测构建 A1、A2、A3\n",
    "        dataset_blend_test_j[:,i] = clf.predict_proba(X_predict)[:,1]     # 用测试集的预测构建 B1\\B2\\B3\n",
    "        \n",
    "    # 对于测试集，直接用这k个模型的预测值均值作为新特征\n",
    "    dataset_blend_test[:,j] = dataset_blend_test_j.mean(1)     # 将测试集的每一次预测取均值作为 B1\\B2\\B3\n",
    "    print('val auc Score: %f'%roc_auc_score(y_predict,dataset_blend_test[:,j]))\n",
    "    \n",
    "# 第二重训练预测    \n",
    "clf = LogisticRegression(solver='lbfgs')\n",
    "clf.fit(dataset_blend_train,y)\n",
    "y_submission = clf.predict_proba(dataset_blend_test)[:,1]\n",
    "print('Val auc Score of Stacking:%f'%(roc_auc_score(y_predict,y_submission)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlxtend\n",
      "  Downloading https://files.pythonhosted.org/packages/86/30/781c0b962a70848db83339567ecab656638c62f05adb064cb33c0ae49244/mlxtend-0.18.0-py2.py3-none-any.whl (1.3MB)\n",
      "Requirement already satisfied: scipy>=1.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from mlxtend) (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.16.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from mlxtend) (1.16.2)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from mlxtend) (0.24.2)\n",
      "Requirement already satisfied: scikit-learn>=0.20.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from mlxtend) (0.20.3)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from mlxtend) (0.17.0)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from mlxtend) (3.0.3)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from mlxtend) (40.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2011k in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2018.9)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.0.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.3.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.5.0->pandas>=0.24.2->mlxtend) (1.12.0)\n",
      "Installing collected packages: mlxtend\n",
      "Successfully installed mlxtend-0.18.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.classifier import StackingClassifier\n",
    "clf1 = KNeighborsClassifier(n_neighbors=1)\n",
    "clf2 = ···\n",
    "clf3 = ···\n",
    "lr = LogisticRegression()\n",
    "sclf = StackingClassifier(classifiers=[clf1,clf2,clf3],   # 三个基分类器\n",
    "                          meta_classifier=lr        # 一个次级分类器\n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 融合·涉及多个层面"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1).结果层面的融合：根据结果的得分进行加权融合，条件是模型结果的分要比较近似，结果差异要比较大。   \n",
    "2).特征层面融合：准确说叫分割，把特征进行切分给不同的特征。   \n",
    "3).模型层面融合：堆叠，最好不同模型类型要有一定差异。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 硬投票"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对多个模型直接进行投票，不区分模型结果的相对重要度，最终投票数最多的类为要被预测的类\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "x = iris.data\n",
    "y = iris.target\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3)\n",
    "clf1 = XGBClassifier(learnig_rate=0.1,n_estimators=150,max_depth=0.3,min_child_weight=2,subsample=0.7,\n",
    "                    colsample_bytree=0.6,objective='binary:logistic')\n",
    "clf2 = RandomForestClassifier(n_estimators=50,max_depth=1,min_samples_split=4,min_samples_leaf=63,oob_score=True)\n",
    "clf3 = SVC(C=0.1)\n",
    "\n",
    "# 硬投票\n",
    "eclf = VotingClassifier(estimators=[('xgb',clf1),('rf',clf2),('svc',clf3)],voting='hard')\n",
    "for clf,label in zip([clf1,clf2,clf3,eclf],['XGBBoosting','Random Forest','SVM','Ensemble']):\n",
    "    scores = cross_val_score(clf,x,y,cv=5,scoring='accuracy')\n",
    "    print('Accuracy:%0.2 (+/- %0.2f)[%s]'%(scores.mean(),scores.std(),label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 软投票"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 软投票：同硬投票，增加了设置权重的功能，可以为不同模型设置不同权重，进而区分模型不同的重要性\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "x = iris.data\n",
    "y = iris.target\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3)\n",
    "clf1 = XGBClassifier(learnig_rate=0.1,n_estimators=150,max_depth=0.3,min_child_weight=2,subsample=0.7,\n",
    "                    colsample_bytree=0.6,objective='binary:logistic')\n",
    "clf2 = RandomForestClassifier(n_estimators=50,max_depth=1,min_samples_split=4,min_samples_leaf=63,oob_score=True)\n",
    "clf3 = SVC(C=0.1)\n",
    "\n",
    "# 软投票\n",
    "eclf = VotingClassifier(estimators=[('xgb',clf1),('rf',clf2),('svc',clf3)],voting='soft',weight=[2,1,1])\n",
    "clf1.fit(x_train,y_train)\n",
    "for clf,label in zip([clf1,clf2,clf3,eclf],['XGBBoosting','Random Forest','SVM','Ensemble']):\n",
    "    scores = cross_val_score(clf,x,y,cv=5,scoring='accuracy')\n",
    "    print('Accuracy:%0.2 (+/- %0.2f)[%s]'%(scores.mean(),scores.std(),label))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
